{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Set, Optional\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from numpy.typing import NDArray, ArrayLike\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "import click\n",
    "import hdbscan\n",
    "import os\n",
    "import logging\n",
    "from random import sample\n",
    "import dill\n",
    "\n",
    "def missing_character(character):\n",
    "    return  \"\"\n",
    "\n",
    "\n",
    "def process_playlist_names(playlist_names: List[str]) -> List[List[str]]:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    printable = set(string.printable)\n",
    "    playlist_names = [''.join(filter(lambda sign: sign in printable, name)) for name in playlist_names]\n",
    "    playlist_names = [word_tokenize(sentence) for sentence in tqdm(playlist_names)]\n",
    "    playlist_names = [list(filter(lambda word: word.lower() not in stop_words, sentence)) for sentence in playlist_names]\n",
    "    return playlist_names\n",
    "\n",
    "\n",
    "def prepare_embedding_dict(model: Word2Vec) -> Dict[str, ArrayLike]:\n",
    "    embeddings = {word: np.array(embedding) for word, embedding in zip(model.wv.index_to_key, model.wv)}\n",
    "    return embeddings\n",
    "\n",
    "def embed_playlists(embeddings_dict: Dict[str, ArrayLike], playlist_names: List, playlist_len=10):\n",
    "    def embed_playlist(name):\n",
    "        return embeddings_dict[name]\n",
    "    embedded_playlists = [np.array(list(map(embed_playlist, name[:playlist_len]))).flatten() for name in playlist_names]\n",
    "    max_name_len = max(list(map(len, embedded_playlists)))\n",
    "    embedded_playlists = np.array(list(map(lambda embedding: np.pad(embedding, (0, max_name_len - len(embedding)), 'constant', constant_values=(0,0)), embedded_playlists)))\n",
    "    return embedded_playlists\n",
    "\n",
    "def recommend_coldstart_cluster(clusterer: hdbscan.HDBSCAN, pca: PCA, playlist_name: str, embeddings_dict: Dict, max_name_len=100) -> int:\n",
    "    playlist_names = process_playlist_names([playlist_name,  ])[0]\n",
    "    print(f\"playlist_names 1 {playlist_names}\")\n",
    "    playlist_names = playlist_names[:10]\n",
    "    print(f\"playlist_names 2 {playlist_names}\")\n",
    "    playlist_embedding = np.array(list(map(lambda name: embeddings_dict[name], playlist_names))).flatten()\n",
    "    print(f\"playlist_embedding 1 {playlist_embedding}\")\n",
    "    playlist_embedding = playlist_embedding[:max_name_len]\n",
    "    print(f\"playlist_embedding 2 {playlist_embedding}\")\n",
    "    playlist_embedding = np.pad(playlist_embedding, (0, max_name_len - len(playlist_embedding)), 'constant', constant_values=(0,0)).reshape(1, -1)\n",
    "    print(f\"playlist_embedding 3 {playlist_embedding}\")\n",
    "    playlist_embedding = pca.transform(playlist_embedding)\n",
    "    print(f\"playlist_embedding 4 {playlist_embedding}\")\n",
    "    print(type(playlist_embedding))\n",
    "    labels, probs = hdbscan.approximate_predict(clusterer, playlist_embedding)\n",
    "    print(labels, probs)\n",
    "    probs = hdbscan.membership_vector(clusterer, playlist_embedding)\n",
    "    return np.argmax(probs)\n",
    "\n",
    "def select_n_from_cluster(clustered_tracks: Dict[int, Set[int]], cluster_id: int, n: int= 50):\n",
    "    tracks_set = clustered_tracks[cluster_id]\n",
    "    return sample(tracks_set, n)\n",
    "\n",
    "def cluster_tracks(labels: List[int], playlists: List[List[int]]) -> Dict[int, Set[int]]:\n",
    "    clustered_playlists = {}\n",
    "    for label, playlist in tqdm(zip(labels, playlists)):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        if label not in clustered_playlists:\n",
    "            clustered_playlists[label] = set()\n",
    "        for track in playlist:\n",
    "            if track == -1:\n",
    "                continue\n",
    "            clustered_playlists[label].add(track)\n",
    "    return clustered_playlists\n",
    "\n",
    "class ColdstartRecommender:\n",
    "    def __init__(self, embeddings_dict: Dict[str, List[int]], pca: PCA, clusterer: hdbscan.HDBSCAN, clustered_tracks: Dict[int, Set[int]], songs_encodings: Dict[int, str]):\n",
    "        self._embeddings_dict = defaultdict(lambda _: np.zeros(10), embeddings_dict)\n",
    "        self._pca = pca\n",
    "        self._clusterer = clusterer\n",
    "        self._clustered_tracks = defaultdict(lambda x: np.zeros(100), clustered_tracks)\n",
    "        self._songs_encodings = defaultdict(lambda x: -1, songs_encodings)\n",
    "    \n",
    "    def recommend_n_tracks(self, playlist_name: str, n: Optional[int]=50):\n",
    "        cluster_id = recommend_coldstart_cluster(self._clusterer, self._pca, playlist_name, self._embeddings_dict)\n",
    "        logging.info(f\"Cluster_id: {cluster_id}\")\n",
    "        track_ids = select_n_from_cluster(self._clustered_tracks, cluster_id)\n",
    "        logging.info(f\"track_ids: {track_ids}\")\n",
    "        track_uris = [self._songs_encodings[track_id] for track_id in track_ids]\n",
    "        logging.info(f\"Track_uris: {track_uris}\")\n",
    "        return track_uris\n",
    "\n",
    "def missing_song_encoding(track):\n",
    "    return -1\n",
    "\n",
    "def empty_track():\n",
    "    return -1\n",
    "\n",
    "def load_songs_encodings(input_path: str) -> Dict[str, int]:\n",
    "    songs_encodings_df = pd.read_csv(input_path, index_col=False)\n",
    "    songs_encodings = defaultdict(empty_track)\n",
    "    for track_uri, track_encoding in zip(songs_encodings_df.track_uris, songs_encodings_df.track_encoding):\n",
    "        songs_encodings[track_uri] = track_encoding\n",
    "    return songs_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/processed\"\n",
    "playlist_names = pd.read_csv(os.path.join(input_filepath, \"playlist_names.csv\"))[\"0\"].to_numpy(dtype=str)\n",
    "playlists = pd.read_csv(os.path.join(input_filepath, \"playlists.csv\")).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_encodings = load_songs_encodings(os.path.join(input_filepath, \"songs_encodings.csv\"))\n",
    "songs_encodings = {track_id: track_uri for track_uri, track_id in songs_encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:41<00:00, 24096.47it/s]\n"
     ]
    }
   ],
   "source": [
    "playlist_names = process_playlist_names(playlist_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(playlist_names, min_count=1, vector_size=10, window=5)\n",
    "embeddings_dict = prepare_embedding_dict(model)\n",
    "embedded_playlists = embed_playlists(embeddings_dict, playlist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "reduced_pn = pca.fit_transform(embedded_playlists)[:200000, :]\n",
    "print(reduced_pn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:05, 17281.00it/s]\n"
     ]
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=1, prediction_data=True)\n",
    "clusterer.fit(reduced_pn)\n",
    "labels = clusterer.labels_\n",
    "clustered_tracks = cluster_tracks(labels, playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4696.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playlist_names 1 ['rock', 'roll']\n",
      "playlist_names 2 ['rock', 'roll']\n",
      "playlist_embedding 1 [-1.4188551   0.5192034   0.7722586  -2.0165107  -0.48576212  0.6706748\n",
      "  2.921494    5.236725   -2.1955607   0.17957498  0.8782166   1.4520342\n",
      "  1.5706425  -1.3946004   3.0239232   0.2817061   0.28467435  2.5714927\n",
      " -0.03775601 -0.66250724]\n",
      "playlist_embedding 2 [-1.4188551   0.5192034   0.7722586  -2.0165107  -0.48576212  0.6706748\n",
      "  2.921494    5.236725   -2.1955607   0.17957498  0.8782166   1.4520342\n",
      "  1.5706425  -1.3946004   3.0239232   0.2817061   0.28467435  2.5714927\n",
      " -0.03775601 -0.66250724]\n",
      "playlist_embedding 3 [[-1.4188551   0.5192034   0.7722586  -2.0165107  -0.48576212  0.6706748\n",
      "   2.921494    5.236725   -2.1955607   0.17957498  0.8782166   1.4520342\n",
      "   1.5706425  -1.3946004   3.0239232   0.2817061   0.28467435  2.5714927\n",
      "  -0.03775601 -0.66250724  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n",
      "playlist_embedding 4 [[ 1.8816602   2.51318921  1.10790765 -1.16375961 -1.54709454 -0.39717931\n",
      "  -1.80779251  0.02289256 -0.95942723  3.58608508]]\n",
      "<class 'numpy.ndarray'>\n",
      "[430] [0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/env/lib/python3.9/site-packages/hdbscan/prediction.py:581: RuntimeWarning: All-NaN slice encountered\n",
      "  outlier_vec = outlier_membership_vector(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spotify:track:629Cjw0fUyZUMkBjnjttDR', 'spotify:track:79XrkTOfV1AqySNjVlygpW', 'spotify:track:5iSEsR6NKjlC9SrIJkyL3k', 'spotify:track:2NRRrr8ylDK38KD3Ffbw4K', 'spotify:track:3qX5utZrFzl2bgQnO8PlhJ', 'spotify:track:57kozn0j4DL3toKrqKQY0U', 'spotify:track:2LQrzHAiBCk2PUgxmYzfDQ', 'spotify:track:68oUQRwGJGExtkpaSvSbgb', 'spotify:track:75kV29N3NsJIOkfuIy0113', 'spotify:track:0of4x5P2ASi3xTvPMQlVQX', 'spotify:track:1JdPcAnG1GfiPzRDNplizS', 'spotify:track:1RUTIdTnFs8lHSc0Zr4UJB', 'spotify:track:7sg9ToL94GAiksETi5GZGz', 'spotify:track:6ynvA6fa4Xk3oV1GNqIN9x', 'spotify:track:3DmNkgOHMlCvPZnuC5fFkT', 'spotify:track:1GaYqv2NMMlVbG3ewJQ4A6', 'spotify:track:29p4HuJyGOzJgvJ9hVwDhD', 'spotify:track:48bzk8bCl0uEemd6Zbc7ct', 'spotify:track:6exNsuGkhyvjyBIiu3eOOz', 'spotify:track:0xjkgYSzHjBZNvyUaC9cXX', 'spotify:track:7b8YWIjK1JEtZXNjSf2ZU1', 'spotify:track:1TtvKn8PytKPzfIh1MGS4e', 'spotify:track:2Sb8qO1M5pafAjKtBXmRpQ', 'spotify:track:3up4BXUfgvKzTRzjpdByko', 'spotify:track:4HsOnvLjiugAuhmmlJDEeQ', 'spotify:track:2aCDeO5o0pPWt2w9IBy2tI', 'spotify:track:0uGEDEO3GjRcnZLFvUxKuA', 'spotify:track:74ndF9FOuzDY93Vv6Vtgfh', 'spotify:track:4zLSt8HRRKdXOgDQX0v3iF', 'spotify:track:7xgfSlAPUouBAquQZkAUdq', 'spotify:track:7umIxTYJ04JkOnLYQzp1BS', 'spotify:track:3WS7spXVlbeC5kjePmHMQW', 'spotify:track:4c7aUCM1i727Z74LBi02rz', 'spotify:track:3taCbWWTilb7eNMsAzOBq4', 'spotify:track:2pjC9vd00ClAk3UHa4cZvk', 'spotify:track:1sUwhtWUTfQzk4ISxNRaB1', 'spotify:track:5ZNth4o3YvTIMs9KWltgFh', 'spotify:track:2ttOFglLynQA0J1B7RhlgX', 'spotify:track:44kxtKjtqycqi1INVYl21D', 'spotify:track:7jIbxV12Jl34GtMmiwQela', 'spotify:track:3x7rZpejhzTFAEGZiQb49n', 'spotify:track:5MBCJXkXwOUPOoSS13831y', 'spotify:track:49OvyOSR3SZJHfLMbkVvIC', 'spotify:track:1cCbsojaA6GIT7Y3zuMJ1q', 'spotify:track:7wwifjNAb172PtDpKK3CoR', 'spotify:track:5z1OWvr9Sd3wjVDIaROHyo', 'spotify:track:0vSVDF2fHaxL2L9eEmRdAK', 'spotify:track:3cg38isdTrBH63B4BMywsw', 'spotify:track:3jEPu6FD1icy9cLllhB2XK', 'spotify:track:2AS0465xJT8zJbrQ4pHP96']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_582224/223180242.py:67: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  return sample(tracks_set, n)\n"
     ]
    }
   ],
   "source": [
    "coldstart_model = ColdstartRecommender(embeddings_dict, pca, clusterer, clustered_tracks, songs_encodings)\n",
    "print(coldstart_model.recommend_n_tracks(\"rock and roll\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 5459, 1394: 46134, 948: 1010, 1109: 1270}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "d = dict(Counter(labels))\n",
    "d = {k: v for k, v in d.items() if v > 1000}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Any\n",
    "def load_pickle(input_path) -> Any:\n",
    "    with open(input_path, 'rb+') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def save_pickle(object: Any, output_path: str):\n",
    "    with open(output_path, 'wb+') as file:\n",
    "        pickle.dump(object, file)\n",
    "\n",
    "model_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/models/coldstart\"\n",
    "save_pickle(embeddings_dict, os.path.join(model_filepath, \"embedding.pkl\"))\n",
    "save_pickle(pca, os.path.join(model_filepath, \"pca.pkl\"))\n",
    "save_pickle(clusterer, os.path.join(model_filepath, \"clusterer.pkl\"))\n",
    "save_pickle(clustered_tracks, os.path.join(model_filepath, \"clustered_tracks.pkl\"))\n",
    "save_pickle(songs_encodings, os.path.join(model_filepath, \"songs_encodings.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "520163f1cd47558842bbeb3d8018629964a373bd06cc7061edb7366f9d3fb8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
