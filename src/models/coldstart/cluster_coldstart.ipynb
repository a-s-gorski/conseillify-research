{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Set\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from numpy.typing import NDArray, ArrayLike\n",
    "from collections import defaultdict\n",
    "import hdbscan\n",
    "from collections import Counter\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_names_path = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/processed/playlist_names.csv\"\n",
    "playlists_content_path = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/processed/playlists.csv\"\n",
    "model_path = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/models/coldstart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_playlist_names(playlist_names: List[str]) -> List[List[str]]:\n",
    "    printable = set(string.printable)\n",
    "    playlist_names = [''.join(filter(lambda sign: sign in printable, name)) for name in playlist_names]\n",
    "    playlist_names = [word_tokenize(sentence) for sentence in tqdm(playlist_names)]\n",
    "    playlist_names = [list(filter(lambda word: word not in stop_words, sentence)) for sentence in playlist_names]\n",
    "    return playlist_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:43<00:00, 22897.98it/s]\n"
     ]
    }
   ],
   "source": [
    "playlist_names = pd.read_csv(playlists_names_path)[\"0\"].to_numpy(dtype=str)\n",
    "playlist_names = process_playlist_names(playlist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622472, 2: 297594, 3: 43999, 0: 17694, 4: 10584, 5: 4462, 6: 1470, 7: 658, 8: 322, 9: 279, 11: 139, 10: 132, 12: 90, 14: 24, 13: 23, 15: 12, 18: 7, 19: 6, 20: 5, 17: 4, 16: 4, 21: 4, 23: 2, 26: 2, 33: 2, 29: 2, 92: 1, 61: 1, 40: 1, 22: 1, 31: 1, 30: 1, 24: 1, 28: 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(list(map(len, playlist_names))))\n",
    "default_playlist_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(playlist_names, min_count=1, vector_size=10, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_embedding_dict(model: Word2Vec) -> Dict[str, ArrayLike]:\n",
    "    def missing():\n",
    "        return \"\"\n",
    "    embeddings = defaultdict(missing, {word: np.array(embedding) for word, embedding in zip(model.wv.index_to_key, model.wv)})\n",
    "    return embeddings\n",
    "embeddings_dict = prepare_embedding_dict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_playlists(embeddings_dict: Dict[str, ArrayLike], playlist_names: List, playlist_len=10):\n",
    "    def embed_playlist(name):\n",
    "        return embeddings_dict[name]\n",
    "    embedded_playlists = [np.array(list(map(embed_playlist, name[:playlist_len]))).flatten() for name in playlist_names]\n",
    "    max_name_len = max(list(map(len, embedded_playlists)))\n",
    "    embedded_playlists = np.array(list(map(lambda embedding: np.pad(embedding, (0, max_name_len - len(embedding)), 'constant', constant_values=(0,0)), embedded_playlists)))\n",
    "    return embedded_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_playlists = embed_playlists(embeddings_dict, playlist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_names = pca.fit_transform(embedded_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(rd_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.5, prediction_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HDBSCAN(cluster_selection_epsilon=0.5, prediction_data=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HDBSCAN</label><div class=\"sk-toggleable__content\"><pre>HDBSCAN(cluster_selection_epsilon=0.5, prediction_data=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HDBSCAN(cluster_selection_epsilon=0.5, prediction_data=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.fit(rd_names[:1000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_coldstart_cluster(clusterer: hdbscan.HDBSCAN, pca: PCA, playlist_name: str, embeddigns_dict: Dict, playlist_len: int = 10, max_name_len=100):\n",
    "    playlist_names = process_playlist_names([playlist_name,  ])[0]\n",
    "    playlist_names = playlist_names[:10]\n",
    "    playlist_embedding = np.array(list(map(lambda name: embeddings_dict[name], playlist_names))).flatten()\n",
    "    playlist_embedding = playlist_embedding[:max_name_len]\n",
    "    playlist_embedding = np.pad(playlist_embedding, (0, max_name_len - len(playlist_embedding)), 'constant', constant_values=(0,0)).reshape(1, -1)\n",
    "    playlist_embedding = pca.transform(playlist_embedding)\n",
    "    probs = hdbscan.membership_vector(clusterer, playlist_embedding)\n",
    "    return np.argmax(probs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3862.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "playlist_name = \"Music\"\n",
    "best_cluster = recommend_coldstart_cluster(clusterer, pca, playlist_name, embeddings_dict)\n",
    "print(best_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.read_csv(playlists_content_path).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clusterer.labels_\n",
    "def cluster_tracks(labels: List[int], playlists: List[List[int]]) -> Dict[int, Set[int]]:\n",
    "    clustered_playlists = {}\n",
    "    for label, playlist in zip(labels, playlists):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        if label not in clustered_playlists:\n",
    "            clustered_playlists[label] = set()\n",
    "        for track in playlist:\n",
    "            if track == -1:\n",
    "                continue\n",
    "            clustered_playlists[label].add(track)\n",
    "    return clustered_playlists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -1}\n",
      "[607, 462, 502, 14109, 1155, 474, 279, 215, 380, 493, 125, 573, 631, 208, 165, 495, 413, 1034, 472, 595]\n"
     ]
    }
   ],
   "source": [
    "clustered_tracks = cluster_tracks(labels, playlists)\n",
    "print(list(map(len, list(clustered_tracks.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_from_cluster(clustered_tracks: Dict[int, Set[int]], cluster_id: int, n: int= 50):\n",
    "    tracks_set = clustered_tracks[cluster_id]\n",
    "    return sample(tracks_set, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[987773, 676176, 1939272, 675136, 953736, 1538475, 2067133, 1106812, 732167, 722890, 1625901, 1102992, 613229, 1863806, 1918775, 582371, 1499968, 1159763, 1746837, 84929, 473714, 2139062, 2142326, 2093239, 1330007, 353917, 2161195, 847267, 1072016, 740451, 2176113, 1465694, 317446, 203409, 1733184, 575192, 1238937, 1645661, 1086735, 2199623, 831958, 72455, 580455, 1568336, 1479534, 958651, 409452, 1659903, 2027543, 1474887, 807555, 440767, 230671, 2155488, 2245255, 908345, 2127845, 1328248, 1301548, 2045374, 917345, 1827503, 774841, 2008960, 2153143, 1599427, 213693, 380179, 903818, 645458, 2077095, 282241, 144638, 1607091, 2130560, 1112955, 2086712, 1384601, 473614, 424818, 1138221, 1384251, 1199888, 402772, 2001633, 1451744, 357029, 1588378, 67979, 1348628, 596553, 33272, 1288827, 66835, 118057, 155883, 424904, 629415, 56374, 752125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33074/3057622463.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  return sample(tracks_set, n)\n"
     ]
    }
   ],
   "source": [
    "tracks = select_n_from_cluster(clustered_tracks, best_cluster, 100)\n",
    "print(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "520163f1cd47558842bbeb3d8018629964a373bd06cc7061edb7366f9d3fb8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
