{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray, ArrayLike\n",
    "from typing import Dict, List, Tuple, Any\n",
    "# from ..candidate_generation.generate_candidates import extract_relevant, extract_n_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_n_tracks(model: LightFM, user_id: int, tracks_shape: int, n_tracks: int = 5):\n",
    "    predictions = model.predict(user_id, np.arange(1, tracks_shape))\n",
    "    predictions = [(score, index) for index, score in enumerate(predictions)]\n",
    "    predictions.sort(reverse=False)\n",
    "    predictions = predictions[:n_tracks]\n",
    "    predictions = [index for _, index in predictions]\n",
    "    return predictions\n",
    "\n",
    "def extract_relevant(playlists: NDArray, tracks: List[int], songs_features: NDArray, user_playlist: ArrayLike) -> Tuple[Any, ArrayLike, NDArray, Dict[Any, int]]:\n",
    "    def encode(track_encodings: Dict, track: int):\n",
    "        if track == 0 or track not in track_encodings:\n",
    "            return 0\n",
    "        return track_encodings[track]\n",
    "    tracks_set = set(tracks)\n",
    "    relevant_playlists = [user_playlist, ]\n",
    "    # extracting relevant playlists\n",
    "    for playlist in playlists:\n",
    "        if set(playlist) & set(tracks_set):\n",
    "            relevant_playlists.append(playlist)\n",
    "    # extracting all relevant tracks\n",
    "    relevant_tracks = set(np.array(relevant_playlists).flatten())\n",
    "    relevant_tracks.discard(0)\n",
    "    tracks_encodings = {track: index + 1 for index, track in enumerate(relevant_tracks)}\n",
    "    encode_vectorizer = np.vectorize(encode)\n",
    "    relevant_playlists = encode_vectorizer(tracks_encodings, relevant_playlists)\n",
    "    relevant_tracks_features = []\n",
    "    for sf in songs_features:\n",
    "        if sf[-1] in relevant_tracks:\n",
    "            sf = sf[1:]\n",
    "            sf[-1] = tracks_encodings[sf[-1]]\n",
    "            relevant_tracks_features.append(sf)\n",
    "    relevant_tracks_features = np.array(relevant_tracks_features)\n",
    "    return relevant_playlists, np.array(list(relevant_tracks)), relevant_tracks_features, tracks_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath = \"../../../data/predictions/candidate_generation\"\n",
    "model_filepath = \"../../../models/learn_to_rank\"\n",
    "output_filepath = \"../../../data/predictions/learn_to_rank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(os.path.join(input_filepath, \"features.csv\"), index_col=False).to_numpy()[:, 1:12]\n",
    "playlists = pd.read_csv(os.path.join(input_filepath, \"playlists.csv\"), index_col=False).to_numpy()\n",
    "user_playlist = pd.read_csv(os.path.join(input_filepath, \"user_playlist.csv\"), index_col=False).to_numpy()[:, 1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USERS = playlists.shape[0]\n",
    "unique_tracks = set(playlists.flatten())\n",
    "unique_tracks.discard(0)\n",
    "N_ITEMS = len(unique_tracks)\n",
    "N_FEATURES = features.shape[1]\n",
    "interactions_tuples = np.array([(user_id, track_id, 1) for user_id, playlist in enumerate(playlists) for track_id in playlist if track_id != 0])\n",
    "features_tuples = np.array([(item_id+1, {feature_id: feature_value} )for item_id, f in enumerate(features) for feature_id, feature_value in enumerate(f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233560 1354160 11 (23993047, 3) (14895760, 2)\n"
     ]
    }
   ],
   "source": [
    "print(N_USERS, N_ITEMS, N_FEATURES, interactions_tuples.shape, features_tuples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(item_identity_features=True)\n",
    "dataset.fit(users=np.arange(0, N_USERS), items=np.arange(1, N_ITEMS+1), item_features=np.arange(0, N_FEATURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions, _ = dataset.build_interactions(interactions_tuples)\n",
    "item_features = dataset.build_item_features(features_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:48<00:00, 48.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fbcdd7360a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=2, loss='warp')\n",
    "model.fit(interactions, item_features=item_features, epochs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [00:00<00:00, 167.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fbcdd7360a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_playlist_tuples = [(0, track_id, 1) for track_id in user_playlist if track_id != 0]\n",
    "user_interactions, _ = dataset.build_interactions(user_playlist_tuples)\n",
    "model.fit_partial(user_interactions, item_features=item_features, epochs=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = extract_n_tracks(model, 0, user_interactions.shape[0], 100)\n",
    "relevant_playlists, tracks, features, encodings = extract_relevant(playlists, predictions, features, user_playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_playlist = np.array([encodings[track] for track in user_playlist if track in encodings])\n",
    "user_playlist = np.pad(user_playlist, (0, 375-len(user_playlist)), constant_values=(0,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13472, 34304, 0, 24934, 25549, 23502, 35410, 15315, 4569, 30939, 12669}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(user_playlist.flatten()))\n",
    "print(set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "520163f1cd47558842bbeb3d8018629964a373bd06cc7061edb7366f9d3fb8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
