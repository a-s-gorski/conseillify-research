{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "from lightfm.data import Dataset\n",
    "import click\n",
    "import os\n",
    "import logging\n",
    "from numpy.typing import NDArray\n",
    "from typing import Any\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "from numpy.typing import ArrayLike, NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(input_path) -> Any:\n",
    "    with open(input_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def save_pickle(object: Any, output_path: str):\n",
    "    with open(output_path, 'wb') as file:\n",
    "        pickle.dump(object, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_input_filepath = \"../../../data/dataset\"\n",
    "playlist_input_filepath = \"../../../data/processed/\"\n",
    "output_filepath = \"../../../data/predictions/candidate_generation\"\n",
    "model_path = \"../../../models/candidate_generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_playlist = pd.read_csv(os.path.join(playlist_input_filepath, \"train_playlists.csv\"), index_col=False).to_numpy()\n",
    "val_playlist = pd.read_csv(os.path.join(playlist_input_filepath, \"val_playlists.csv\"), index_col=False).to_numpy()\n",
    "test_playlist = pd.read_csv(os.path.join(playlist_input_filepath, \"test_playlists.csv\"), index_col=False).to_numpy()\n",
    "all_playlists = pd.read_csv(os.path.join(playlist_input_filepath, \"playlists.csv\"), index_col=False).to_numpy()\n",
    "songs_encodings = pd.read_csv(os.path.join(playlist_input_filepath, \"songs_encodings.csv\"), index_col=False)\n",
    "songs_features = pd.read_csv(os.path.join(playlist_input_filepath, \"songs_features.csv\")).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions = load_npz(os.path.join(interactions_input_filepath, \"train_interactions.npz\"))\n",
    "val_interactions = load_npz(os.path.join(interactions_input_filepath, \"val_interactions.npz\"))\n",
    "test_interactions = load_npz(os.path.join(interactions_input_filepath, \"test_interactions.npz\"))\n",
    "dataset = load_pickle(os.path.join(interactions_input_filepath, \"dataset_lightfm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [04:44<00:00, 142.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f179b3abf40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=2, loss='warp')\n",
    "model.fit(train_interactions, epochs=2, verbose=True)\n",
    "model.fit_partial(val_interactions)\n",
    "model.fit_partial(test_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(model, os.path.join(model_path, \"candidate_generator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_n_tracks(model: LightFM, user_id: int, tracks_shape: int, n_tracks: int = 5):\n",
    "    predictions = model.predict(user_id, np.arange(1, tracks_shape))\n",
    "    predictions = [(score, index) for index, score in enumerate(predictions)]\n",
    "    predictions.sort(reverse=False)\n",
    "    predictions = predictions[:n_tracks]\n",
    "    predictions = [index for _, index in predictions]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = extract_n_tracks(model, 999998, train_interactions.shape[0], 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant(playlists: NDArray, tracks: List[int], songs_encodings: Dict, songs_features: NDArray, user_playlist: ArrayLike) -> Tuple[Any, ArrayLike, NDArray, Dict[Any, int]]:\n",
    "    def encode(track_encodings: Dict, track: int):\n",
    "        if track == 0 or track not in track_encodings:\n",
    "            return 0\n",
    "        return track_encodings[track]\n",
    "    tracks_set = set(tracks)\n",
    "    relevant_playlists = [user_playlist, ]\n",
    "    # extracting relevant playlists\n",
    "    for playlist in playlists:\n",
    "        if set(playlist) & set(tracks_set):\n",
    "            relevant_playlists.append(playlist)\n",
    "    # extracting all relevant tracks\n",
    "    relevant_tracks = set(np.array(relevant_playlists).flatten())\n",
    "    relevant_tracks.discard(0)\n",
    "    tracks_encodings = {track: index + 1 for index, track in enumerate(relevant_tracks)}\n",
    "    encode_vectorizer = np.vectorize(encode)\n",
    "    relevant_playlists = encode_vectorizer(tracks_encodings, relevant_playlists)\n",
    "    relevant_tracks_features = []\n",
    "    for sf in songs_features:\n",
    "        if sf[-1] in relevant_tracks:\n",
    "            sf = sf[1:]\n",
    "            sf[-1] = tracks_encodings[sf[-1]]\n",
    "            relevant_tracks_features.append(sf)\n",
    "    relevant_tracks_features = np.array(relevant_tracks_features)\n",
    "    return relevant_playlists, np.array(list(relevant_tracks)), relevant_tracks_features, tracks_encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_playlists, tracks, features, encodings = extract_relevant(train_playlist, preds, songs_encodings, songs_features, all_playlists[999998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3173, 375)\n",
      "(126858,)\n",
      "(5310, 13)\n",
      "126858\n",
      "{493056, 1207233, 1910306, 1726979, 1796070, 353641, 813485, 1246350, 866480, 1979674}\n",
      "{493056, 1207233, 1910306, 1726979, 0, 1796070, 353641, 813485, 1246350, 866480, 1753143, 1979674, 519453}\n"
     ]
    }
   ],
   "source": [
    "print(relevant_playlists.shape)\n",
    "print(tracks.shape)\n",
    "print(features.shape)\n",
    "print(len(encodings))\n",
    "print(set(tracks) & set(all_playlists[999999]))\n",
    "print(set(all_playlists[999999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375,)\n",
      "[ 40453  13672  80211  46218  73314  38031  78129  97813 109244 112756\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "user_playlist = np.array([encodings[track] for track in all_playlists[999999] if track in encodings])\n",
    "user_playlist = np.pad(user_playlist, (0, 375-len(user_playlist)), constant_values=(0,0))\n",
    "print(user_playlist.shape)\n",
    "print(user_playlist[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(user_playlist).to_csv(os.path.join(output_filepath, \"user_playlist.csv\"))\n",
    "pd.DataFrame(relevant_playlists).to_csv(os.path.join(output_filepath, \"playlists.csv\"), index=False)\n",
    "pd.DataFrame(features).to_csv(os.path.join(output_filepath, \"features.csv\"), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "520163f1cd47558842bbeb3d8018629964a373bd06cc7061edb7366f9d3fb8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
