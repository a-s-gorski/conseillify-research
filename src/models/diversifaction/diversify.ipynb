{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamgorski/anaconda3/envs/rtx_3060-3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from numpy.typing import NDArray, ArrayLike\n",
    "from typing import Optional\n",
    "from builtins import len\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_edges(pos_edges: NDArray, neg_size, max_iterations: Optional[int] = 1000000) -> NDArray:\n",
    "        pos_edges_set = set([tuple(edge) for edge in pos_edges])\n",
    "        neg_edges = set()\n",
    "        min_edge, max_edge = pos_edges.flatten().min(axis=0), pos_edges.flatten().max(axis=0)\n",
    "        iterations = 0\n",
    "        while len(neg_edges) < neg_size and iterations < max_iterations:\n",
    "                start_edge = np.random.randint(min_edge, max_edge)\n",
    "                end_edge = np.random.randint(min_edge, max_edge)\n",
    "                if start_edge != end_edge and (start_edge, end_edge) not in pos_edges_set:\n",
    "                        neg_edges.add((start_edge, end_edge))\n",
    "                iterations += 1\n",
    "        return np.array(list(neg_edges))\n",
    "\n",
    "def generate_candidate_edges(pos_edges: NDArray, neg_edges: NDArray, user_playlist: ArrayLike, n_candidates: Optional[int]=1000, max_iterations: Optional[int]=1000000):\n",
    "        start_candidates = set(user_playlist)\n",
    "        start_candidates.discard(0)\n",
    "        end_candidates = set([track for track in set(pos_edges.flatten()) if track not in start_candidates])\n",
    "        end_candidates.discard(0)\n",
    "        candidates = set()\n",
    "        iterations = 0\n",
    "\n",
    "        pos_edges_set = set(pos_edges.flatten())\n",
    "        neg_edges_set = set(neg_edges.flatten())\n",
    "\n",
    "        \n",
    "        while len(candidates) < n_candidates and iterations < max_iterations:\n",
    "                candidate = (np.random.choice(list(start_candidates), size=1)[0], np.random.choice(list(end_candidates), size=1)[0])\n",
    "                if candidate not in candidates.union(pos_edges_set).union(neg_edges_set):\n",
    "                        candidates.add(candidate)\n",
    "                iterations += 1\n",
    "        return np.array(list(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/predictions/ranking/features.csv\"\n",
    "playlists_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/predictions/ranking/playlists.csv\"\n",
    "user_playlist_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/predictions/ranking/user_playlist.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 218.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34004, 2)\n",
      "torch.Size([27927, 11])\n",
      "(3, 376)\n",
      "(375,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = pd.read_csv(features_filepath, index_col=False).to_numpy()[:, 2:13]\n",
    "features = torch.from_numpy(np.array(features, dtype=np.float64))\n",
    "playlists = pd.read_csv(playlists_filepath).to_numpy()\n",
    "SAMPLE_SIZE = 3\n",
    "sampled_playlists = playlists[np.random.choice(playlists.shape[0], size=SAMPLE_SIZE, replace=False), :]\n",
    "pos_edges = np.array([list(combinations(np.delete(playlist, 0), 2)) for playlist in tqdm(sampled_playlists)]).reshape(-1, 2)\n",
    "pos_edges = np.unique(pos_edges, axis=0)\n",
    "user_playlist = pd.read_csv(user_playlist_filepath).to_numpy()[:, 1]\n",
    "print(pos_edges.shape)\n",
    "print(features.shape)\n",
    "print(sampled_playlists.shape)\n",
    "print(user_playlist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edges = generate_neg_edges(pos_edges, pos_edges.shape[0])\n",
    "candidates = generate_candidate_edges(pos_edges, neg_edges, user_playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54406 54406 13602 13602\n"
     ]
    }
   ],
   "source": [
    "train_pos_edges, test_pos_edges, train_neg_edges, test_neg_edges = train_test_split(pos_edges, neg_edges, test_size=0.2)\n",
    "train_pos_edges = np.array(train_pos_edges)\n",
    "test_pos_edges = np.array(test_pos_edges)\n",
    "train_neg_edges = np.array(train_neg_edges)\n",
    "test_neg_edges = np.array(test_neg_edges)\n",
    "\n",
    "print(train_pos_edges.size, train_neg_edges.size, test_pos_edges.size, test_neg_edges.size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_graph = dgl.graph((train_pos_edges[:, 0].flatten(), train_neg_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "train_neg_graph = dgl.graph((train_neg_edges[:, 0].flatten(), train_neg_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "test_pos_graph = dgl.graph((test_pos_edges[:, 0].flatten(), test_pos_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "test_neg_graph = dgl.graph((test_neg_edges[:, 0].flatten(), test_neg_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "train_start_edges = np.concatenate((train_pos_edges[:, 0], train_neg_edges[:, 0]), axis=0).flatten()\n",
    "train_end_edges = np.concatenate((train_pos_edges[:, 1], train_neg_edges[:, 1]), axis=0).flatten()\n",
    "test_start_edges = np.concatenate((test_pos_edges[:, 0], test_neg_edges[:, 0]), axis=0).flatten()\n",
    "test_end_edges = np.concatenate((test_pos_edges[:, 1], test_pos_edges[:, 1]), axis=0).flatten()\n",
    "train_g = dgl.graph((train_start_edges, train_end_edges), num_nodes=features.shape[0])\n",
    "test_g = dgl.graph((test_start_edges, test_end_edges), num_nodes=features.shape[0])\n",
    "train_pos_graph.ndata['feat']=features\n",
    "train_neg_graph.ndata['feat']=features\n",
    "test_pos_graph.ndata['feat']=features\n",
    "test_neg_graph.ndata['feat']=features\n",
    "train_g.ndata['feat']=features\n",
    "test_g.ndata['feat']=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat.float())\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamgorski/anaconda3/envs/rtx_3060-3.9/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 3.723393440246582\n",
      "In epoch 5, loss: 1.30510675907135\n",
      "In epoch 10, loss: 1.4460320472717285\n",
      "In epoch 15, loss: 1.086094617843628\n",
      "In epoch 20, loss: 0.7561049461364746\n",
      "In epoch 25, loss: 0.6178773641586304\n",
      "In epoch 30, loss: 0.5126681327819824\n",
      "In epoch 35, loss: 0.44930770993232727\n",
      "In epoch 40, loss: 0.4253521263599396\n",
      "In epoch 45, loss: 0.41442540287971497\n",
      "In epoch 50, loss: 0.4095926284790039\n",
      "In epoch 55, loss: 0.4062982201576233\n",
      "In epoch 60, loss: 0.3995200991630554\n",
      "In epoch 65, loss: 0.3938545286655426\n",
      "In epoch 70, loss: 0.38772648572921753\n",
      "In epoch 75, loss: 0.3825594186782837\n",
      "In epoch 80, loss: 0.37719762325286865\n",
      "In epoch 85, loss: 0.37193235754966736\n",
      "In epoch 90, loss: 0.3662301301956177\n",
      "In epoch 95, loss: 0.36018574237823486\n",
      "In epoch 100, loss: 0.3537357449531555\n",
      "In epoch 105, loss: 0.3457789421081543\n",
      "In epoch 110, loss: 0.33734244108200073\n",
      "In epoch 115, loss: 0.33015814423561096\n",
      "In epoch 120, loss: 0.3210482895374298\n",
      "In epoch 125, loss: 0.31232595443725586\n",
      "In epoch 130, loss: 0.3030586838722229\n",
      "In epoch 135, loss: 0.29374340176582336\n",
      "In epoch 140, loss: 0.2848116159439087\n",
      "In epoch 145, loss: 0.2763524353504181\n",
      "In epoch 150, loss: 0.26872843503952026\n",
      "In epoch 155, loss: 0.261894166469574\n",
      "In epoch 160, loss: 0.25612056255340576\n",
      "In epoch 165, loss: 0.25112244486808777\n",
      "In epoch 170, loss: 0.24677303433418274\n",
      "In epoch 175, loss: 0.2429293543100357\n",
      "In epoch 180, loss: 0.23945514857769012\n",
      "In epoch 185, loss: 0.23621371388435364\n",
      "In epoch 190, loss: 0.2330269068479538\n",
      "In epoch 195, loss: 0.22985215485095978\n"
     ]
    }
   ],
   "source": [
    "model = GraphSAGE(train_pos_graph.ndata['feat'].shape[1], 16)\n",
    "pred = MLPPredictor(16)\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "for epoch in range(200):\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_graph, h)\n",
    "    neg_score = pred(train_neg_graph, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(epoch, loss))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.9007852383212283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_graph, h)\n",
    "    neg_score = pred(test_neg_graph, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 999\n"
     ]
    }
   ],
   "source": [
    "candidates_graph = dgl.graph((candidates[:, 0].flatten(), candidates[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "candidates_graph.ndata['feat']=features\n",
    "candidates_preds = pred(candidates_graph, h)\n",
    "preds = candidates_preds.detach()\n",
    "preds = np.sort(preds)[::-1]\n",
    "print(len([p for p in preds if p > 0]), len([p for p in preds if p < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rtx_3060-3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e7c957bbbf40186debaa8300fabc2a62862f4e312f7e7bc2a6e4169c7f6a79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
