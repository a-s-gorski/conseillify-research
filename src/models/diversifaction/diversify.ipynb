{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from numpy.typing import NDArray, ArrayLike\n",
    "from typing import Optional\n",
    "from builtins import len\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_neg_edges(pos_edges: NDArray, neg_size, max_iterations: Optional[int] = 1000000) -> NDArray:\n",
    "        pos_edges_set = set([tuple(edge) for edge in pos_edges])\n",
    "        neg_edges = set()\n",
    "        min_edge, max_edge = pos_edges.flatten().min(axis=0), pos_edges.flatten().max(axis=0)\n",
    "        iterations = 0\n",
    "        while len(neg_edges) < neg_size and iterations < max_iterations:\n",
    "                start_edge = np.random.randint(min_edge, max_edge)\n",
    "                end_edge = np.random.randint(min_edge, max_edge)\n",
    "                if start_edge != end_edge and (start_edge, end_edge) not in pos_edges_set:\n",
    "                        neg_edges.add((start_edge, end_edge))\n",
    "                iterations += 1\n",
    "        return np.array(list(neg_edges))\n",
    "\n",
    "def generate_candidate_edges(pos_edges: NDArray, neg_edges: NDArray, user_playlist: ArrayLike, n_candidates: Optional[int]=1000, max_iterations: Optional[int]=1000000):\n",
    "        start_candidates = set(user_playlist)\n",
    "        start_candidates.discard(0)\n",
    "        end_candidates = set([track for track in set(pos_edges.flatten()) if track not in start_candidates])\n",
    "        end_candidates.discard(0)\n",
    "        candidates = set()\n",
    "        iterations = 0\n",
    "\n",
    "        pos_edges_set = set(pos_edges.flatten())\n",
    "        neg_edges_set = set(neg_edges.flatten())\n",
    "\n",
    "        \n",
    "        while len(candidates) < n_candidates and iterations < max_iterations:\n",
    "                candidate = (np.random.choice(list(start_candidates), size=1)[0], np.random.choice(list(end_candidates), size=1)[0])\n",
    "                if candidate not in candidates.union(pos_edges_set).union(neg_edges_set):\n",
    "                        candidates.add(candidate)\n",
    "                iterations += 1\n",
    "        return np.array(list(candidates))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/predictions/ranking/features.csv\"\n",
    "playlists_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/predictions/ranking/playlists.csv\"\n",
    "user_playlist_filepath = \"/home/adamgorski/Desktop/inzynierka/conseillify/conseillify-research/data/predictions/ranking/user_playlist.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "features = pd.read_csv(features_filepath, index_col=False).to_numpy()[:, 2:13]\n",
    "features = torch.from_numpy(np.array(features, dtype=np.float64))\n",
    "playlists = pd.read_csv(playlists_filepath).to_numpy()\n",
    "SAMPLE_SIZE = 3\n",
    "sampled_playlists = playlists[np.random.choice(playlists.shape[0], size=SAMPLE_SIZE, replace=False), :]\n",
    "pos_edges = np.array([list(combinations(np.delete(playlist, 0), 2)) for playlist in tqdm(sampled_playlists)]).reshape(-1, 2)\n",
    "pos_edges = np.unique(pos_edges, axis=0)\n",
    "user_playlist = pd.read_csv(user_playlist_filepath).to_numpy()[:, 1]\n",
    "print(pos_edges.shape)\n",
    "print(features.shape)\n",
    "print(sampled_playlists.shape)\n",
    "print(user_playlist.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg_edges = generate_neg_edges(pos_edges, pos_edges.shape[0])\n",
    "candidates = generate_candidate_edges(pos_edges, neg_edges, user_playlist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_pos_edges, test_pos_edges, train_neg_edges, test_neg_edges = train_test_split(pos_edges, neg_edges, test_size=0.2)\n",
    "train_pos_edges = np.array(train_pos_edges)\n",
    "test_pos_edges = np.array(test_pos_edges)\n",
    "train_neg_edges = np.array(train_neg_edges)\n",
    "test_neg_edges = np.array(test_neg_edges)\n",
    "\n",
    "print(train_pos_edges.size, train_neg_edges.size, test_pos_edges.size, test_neg_edges.size) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_pos_graph = dgl.graph((train_pos_edges[:, 0].flatten(), train_neg_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "train_neg_graph = dgl.graph((train_neg_edges[:, 0].flatten(), train_neg_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "test_pos_graph = dgl.graph((test_pos_edges[:, 0].flatten(), test_pos_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "test_neg_graph = dgl.graph((test_neg_edges[:, 0].flatten(), test_neg_edges[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "train_start_edges = np.concatenate((train_pos_edges[:, 0], train_neg_edges[:, 0]), axis=0).flatten()\n",
    "train_end_edges = np.concatenate((train_pos_edges[:, 1], train_neg_edges[:, 1]), axis=0).flatten()\n",
    "test_start_edges = np.concatenate((test_pos_edges[:, 0], test_neg_edges[:, 0]), axis=0).flatten()\n",
    "test_end_edges = np.concatenate((test_pos_edges[:, 1], test_pos_edges[:, 1]), axis=0).flatten()\n",
    "train_g = dgl.graph((train_start_edges, train_end_edges), num_nodes=features.shape[0])\n",
    "test_g = dgl.graph((test_start_edges, test_end_edges), num_nodes=features.shape[0])\n",
    "train_pos_graph.ndata['feat']=features\n",
    "train_neg_graph.ndata['feat']=features\n",
    "test_pos_graph.ndata['feat']=features\n",
    "test_neg_graph.ndata['feat']=features\n",
    "train_g.ndata['feat']=features\n",
    "test_g.ndata['feat']=features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat.float())\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_pos_graph.ndata['feat'].shape[1], 16)\n",
    "pred = MLPPredictor(16)\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "for epoch in range(200):\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_graph, h)\n",
    "    neg_score = pred(train_neg_graph, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(epoch, loss))        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_graph, h)\n",
    "    neg_score = pred(test_neg_graph, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "candidates_graph = dgl.graph((candidates[:, 0].flatten(), candidates[:, 1].flatten()), num_nodes=features.shape[0])\n",
    "candidates_graph.ndata['feat']=features\n",
    "candidates_preds = pred(candidates_graph, h)\n",
    "preds = candidates_preds.detach()\n",
    "preds = np.sort(preds)[::-1]\n",
    "print(len([p for p in preds if p > 0]), len([p for p in preds if p < 0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(h))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rtx_3060-3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e7c957bbbf40186debaa8300fabc2a62862f4e312f7e7bc2a6e4169c7f6a79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}